# ==================== LLM Provider Configuration ====================
# Set the default provider: "anthropic", "openai", or "azure"
DEFAULT_LLM_PROVIDER=anthropic

# Optional: Override the default model (otherwise uses provider-specific defaults)
# DEFAULT_LLM_MODEL=claude-sonnet-4-20250514

# ==================== Anthropic Configuration ====================
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# Optional: Override default Anthropic model
# ANTHROPIC_DEFAULT_MODEL=claude-sonnet-4-20250514

# ==================== OpenAI Configuration ====================
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=your-openai-api-key-here

# Optional: Override default OpenAI model
# OPENAI_DEFAULT_MODEL=gpt-4-turbo

# ==================== Azure OpenAI Configuration ====================
# Azure OpenAI credentials - all 4 fields required if using Azure
# AZURE_OPENAI_API_KEY=your-azure-openai-api-key
# AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
# AZURE_OPENAI_API_VERSION=2024-02-15-preview
# AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment-name

# ==================== LangSmith Configuration ====================
# Get your API key from: https://smith.langchain.com/settings
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_API_KEY=your-langsmith-api-key
# LANGCHAIN_PROJECT=contract-draft-poc
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com

# ==================== Notes ====================
# - You only need to configure ONE provider to use the application
# - Uncomment the lines for the provider(s) you want to use
# - Make sure DEFAULT_LLM_PROVIDER matches a configured provider
# - LangSmith tracing is optional but recommended for monitoring
